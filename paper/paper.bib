@article{abbink2018_topology,
  title = {A {{Topology}} of {{Shared Control Systems}}\textemdash{{Finding Common Ground}} in {{Diversity}}},
  author = {Abbink, David A. and Carlson, Tom and Mulder, Mark and {de Winter}, Joost C. F. and Aminravan, Farzad and Gibo, Tricia L. and Boer, Erwin R.},
  year = {2018},
  month = oct,
  volume = {48},
  pages = {509--525},
  issn = {2168-2291, 2168-2305},
  doi = {10.1109/THMS.2018.2791570},
  url = {https://ieeexplore.ieee.org/document/8353134/},
  urldate = {2020-03-20},
  abstract = {Shared control is an increasingly popular approach to facilitate control and communication between humans and intelligent machines. However, there is little consensus in guidelines for design and evaluation of shared control, or even in a definition of what constitutes shared control. This lack of consensus complicates cross fertilization of shared control research between different application domains. This paper provides a definition for shared control in context with previous definitions, and a set of general axioms for design and evaluation of shared control solutions. The utility of the definition and axioms are demonstrated by applying them to four application domains: automotive, robot-assisted surgery, brain\textendash machine interfaces, and learning. Literature is discussed for each of these four domains in light of the proposed definition and axioms. Finally, to facilitate design choices for other applications, we propose a hierarchical framework for shared control that links the shared control literature with traded control, co-operative control, and other human\textendash automation interaction methods. Future work should reveal the generalizability and utility of the proposed shared control framework in designing useful, safe, and comfortable interaction between humans and intelligent machines.},
  journal = {IEEE Transactions on Human-Machine Systems},
  language = {en},
  number = {5}
}

@inproceedings{bazilinskyy2020_coupled,
  title = {Coupled Simulator for Research on the Interaction between Pedestrians and (Automated) Vehicles},
  booktitle = {19th {{Driving Simulation Conference}} ({{DSC}})},
  author = {Bazilinskyy, Pavlo and Kooijman, Lars and Dodou, Dimitra and {de Winter}, J. C. F.},
  year = {2020},
  pages = {7},
  address = {{Antibes, France}},
  abstract = {Driving simulators are regarded as valuable tools for human factors research on automated driving and traffic safety. However, simulators that enable the study of human-human interactions are rare. In this study, we present an open-source coupled simulator developed in Unity. The simulator supports input from head-mounted displays, motion suits, and game controllers. It facilitates research on interactions between pedestrians and humans inside manual and automated vehicles. We present results of a demo experiment on the interaction between a passenger in an automated car equipped with an external human-machine interface, a driver of a manual car, and a pedestrian. We conclude that the newly developed open-source coupled simulator is a promising tool for future human factors research.},
  file = {C\:\\Users\\nwmbeckers\\Dropbox\\library-tud\\Bazilinskyy2020_Coupled simulator for research on the interaction between pedestrians and.pdf},
  language = {en}
}

 @online{wivw-scilab,
 title={Driving Simulation and SILAB},
 url={https://wivw.de/en/silab},
 author={WIVW},
 note={visited on: 2020-09-30},
 year={2020}
 }

 @online{sensodrive,
 title={SensoDrive Force Feedback},
 url={https://www.sensodrive.de/products/force-feedback-products.php},
 author={SensoDrive},
 note={visited on: 2022-01-28},
 year={2022}
 }

@incollection{airsim2017fsr,
author = {Shah, Shital and Dey, Debadeepta and Lovett, Chris and Kapoor, Ashish},
doi = {10.1007/978-3-319-67361-5_40},
pages = {621--635},
title = {{AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles}},
url = {http://link.springer.com/10.1007/978-3-319-67361-5_40},
year = {2018}
}

 @online{lgsvlsim,
 title={LGSVL Simulator},
 url={https://www.lgsvlsimulator.com/},
 author={Advanced Platform Lab at the LG Electronics America R\&D Center},
 note={visited on: 2020-09-30},
 year={2020}
 }

@techreport{kearney2018_multimodal,
  title = {Multi-{{Modal Distributed Simulation Combining Cars}}, {{Bicyclists}}, and {{Pedestrians}}},
  author = {Kearney, Joseph K and Noyce, David A},
  year = {2018},
  pages = {31},
  file = {C\:\\Users\\nwmbeckers\\Zotero\\storage\\IWWH65VN\\Kearney and Noyce - Multi-Modal Distributed Simulation Combining Cars,.pdf},
  language = {en}
}

@inproceedings{dosovitskiy2017_carla,
  title = {{{CARLA}}: {{An Open Urban Driving Simulator}}},
  booktitle = {Proceedings of the 1st {{Annual Conference}} on {{Robot Learning}}},
  author = {Dosovitskiy, Alexey},
  year = {2017},
  pages = {1--16},
  address = {{Mountain View, California}},
  url = {http://proceedings.mlr.press/v78/dosovitskiy17a/dosovitskiy17a.pdf},
  abstract = {We introduce CARLA, an open-source simulator for autonomous driving research. CARLA has been developed from the ground up to support development, training, and validation of autonomous urban driving systems. In addition to open-source code and protocols, CARLA provides open digital assets (urban layouts, buildings, vehicles) that were created for this purpose and can be used freely. The simulation platform supports flexible specification of sensor suites and environmental conditions. We use CARLA to study the performance of three approaches to autonomous driving: a classic modular pipeline, an endto-end model trained via imitation learning, and an end-to-end model trained via reinforcement learning. The approaches are evaluated in controlled scenarios of increasing difficulty, and their performance is examined via metrics provided by CARLA, illustrating the platform's utility for autonomous driving research.},
  file = {C\:\\Users\\nwmbeckers\\Dropbox\\library-tud\\Dosovitskiy2017_CARLA.pdf},
  language = {en}
}

@article{kolekar2020_which,
  title = {Which Parts of the Road Guide Obstacle Avoidance? {{Quantifying}} the Driver's Risk Field},
  shorttitle = {Which Parts of the Road Guide Obstacle Avoidance?},
  author = {Kolekar, Sarvesh and {de Winter}, Joost and Abbink, David},
  year = {2020},
  month = nov,
  volume = {89},
  pages = {103196},
  issn = {00036870},
  doi = {10.1016/j.apergo.2020.103196},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0003687018307373},
  urldate = {2020-09-04},
  abstract = {Gibson and Crooks (1938) argued that a `field of safe travel' could qualitatively explain drivers' steering behavior on straights, curved roads, and while avoiding obstacles. This study aims to quantitatively explain driver behavior while avoiding obstacles on a straight road, and quantify the `Driver's Risk Field' (DRF). In a fixedbased driving simulator, 77 (7 longitudinal and 11 lateral) positions of the obstacles were used to quantify the subjectively perceived and objectively (maximum absolute steering angle) measured DRF for eight partici\- pants. The subjective response was a numerical answer to the question ``How much steering do you think you need at this moment in time?'' The results show that the propagation of the width of the DRF, along the lon\- gitudinal distance, resembled an hourglass shape, and all participants responded to obstacles that were placed beyond the width of the car. This implies that the Driver's Risk Field is wider than the car width.},
  file = {C\:\\Users\\nwmbeckers\\Dropbox\\library-tud\\Kolekar2020_Which parts of the road guide obstacle avoidance_Applied Ergonomics.pdf},
  journal = {Applied Ergonomics},
  language = {en}
}
@techreport{slob2008_stateoftheart,
  title = {State-of-the-Art Driving Simulators, a Literature Survey},
  author = {Slob, JJ},
  year = {2008},
  number = {107},
  type = {DCT report 107}
}

@misc{qtframework,
  title = {{Qt framework}},
  howpublished = "\url{https://www.qt.io/}",
  year = {2020},
  note = "[Online; accessed 19-July-2020]"
}


@article{mulder2012_sharing,
  title = {Sharing {{Control With Haptics}}: {{Seamless Driver Support From Manual}} to {{Automatic Control}}},
  shorttitle = {Sharing {{Control With Haptics}}},
  author = {Mulder, Mark and Abbink, David A. and Boer, Erwin R.},
  year = {2012},
  month = oct,
  volume = {54},
  pages = {786--798},
  issn = {0018-7208, 1547-8181},
  doi = {10.1177/0018720812443984},
  url = {http://journals.sagepub.com/doi/10.1177/0018720812443984},
  urldate = {2020-03-20},
  abstract = {Objective: Haptic shared control was investigated as a human\textendash machine interface that can intuitively share control between drivers and an automatic controller for curve negotiation. Background: As long as automation systems are not fully reliable, a role remains for the driver to be vigilant to the system and the environment to catch any automation errors. The conventional binary switches between supervisory and manual control has many known issues, and haptic shared control is a promising alternative. Method: A total of 42 respondents of varying age and driving experience participated in a driving experiment in a fixed-base simulator, in which curve negotiation behavior during shared control was compared to during manual control, as well as to three haptic tunings of an automatic controller without driver intervention. Results: Under the experimental conditions studied, the main beneficial effect of haptic shared control compared to manual control was that less control activity (16\% in steering wheel reversal rate, 15\% in standard deviation of steering wheel angle) was needed for realizing an improved safety performance (e.g., 11\% in peak lateral error). Full automation removed the need for any human control activity and improved safety performance (e.g., 35\% in peak lateral error) but put the human in a supervisory position. Conclusion: Haptic shared control kept the driver in the loop, with enhanced performance at reduced control activity, mitigating the known issues that plague full automation.},
  file = {C\:\\Users\\nwmbeckers\\Dropbox\\library-tud\\Mulder2012_Sharing Control With Haptics_Hum Factors.pdf},
  journal = {Human Factors: The Journal of the Human Factors and Ergonomics Society},
  language = {en},
  number = {5}
}





@article{zgonnikov2020_should,
  title = {Should {{I}} Stay or Should {{I}} Go? {{Evidence}} Accumulation Drives Decision Making in Human Drivers},
  shorttitle = {Should {{I}} Stay or Should {{I}} Go?},
  author = {Zgonnikov, Arkady and Abbink, David and Markkula, Gustav},
  year = {2020},
  month = jul,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/p8dxn},
  url = {https://osf.io/p8dxn},
  urldate = {2020-09-21},
  abstract = {Laboratory studies of abstract, highly controlled tasks point towards noisy evidence accumulation as a key mechanism governing decision making. Yet it is unclear whether the cognitive processes implicated in simple, isolated decisions in the lab are as paramount to decisions that are ingrained in more complex behaviors, such as driving. Here we aim to address the gap between modern cognitive models of decision making and studies of naturalistic decision making in drivers, which so far have provided only limited insight into the underlying cognitive processes. We investigate drivers' decision making during unprotected left turns, and model the cognitive process driving these decisions. Our model builds on the classical drift-diffusion model, and emphasizes, first, the drift rate linked to the relevant perceptual quantities dynamically sampled from the environment, and, second, collapsing decision boundaries reflecting the dynamic constraints imposed on the decision maker's response by the environment. We show that the model explains the observed decision outcomes and response times, as well as substantial individual differences in those. Through cross-validation, we demonstrate that the model not only explains the data, but also generalizes to out-of-sample conditions, effectively providing a way to predict human drivers' behavior in real time. Our results reveal the cognitive mechanisms of gap acceptance decisions in human drivers, and exemplify how simple cognitive process models can help us to understand human behavior in complex real-world tasks.},
  file = {C\:\\Users\\nwmbeckers\\Zotero\\storage\\TCHVCQ5U\\Zgonnikov et al. - 2020 - Should I stay or should I go Evidence accumulatio.pdf},
  language = {en},
  type = {Preprint}
}

@incollection{vanpaassen2017_four,
  title = {Four {{Design Choices}} for {{Haptic Shared Control}}},
  booktitle = {Advances in {{Aviation Psychology}}, {{Volume}} 2: {{Using Scientific Methods}} to {{Address Practical Human Factors Needs}}},
  author = {{van Paassen}, Marinus M. and Boink, Rolf and Abbink, David A. and Mulder, Mark and Mulder, Max},
  editor = {Vidulich, Michael A. and Tsang, Pamela S. and Flach, John},
  year = {2017},
  month = may,
  edition = {First},
  pages = {237--254},
  publisher = {{Routledge}},
  doi = {10.4324/9781315565712},
  url = {https://www.taylorfrancis.com/books/9781317185208},
  urldate = {2020-05-22},
  file = {C\:\\Users\\nwmbeckers\\Dropbox\\library-tud\\van Paassen2017_Four Design Choices for Haptic Shared Control.pdf},
  isbn = {978-1-315-56571-2},
  language = {en}
}

@inproceedings{vanpaassen2000_dueca,
  title = {{{DUECA}} - {{Data}}-Driven Activation in Distributed Real-Time Computation},
  booktitle = {Modeling and {{Simulation Technologies Conference}}},
  author = {{van Paassen}, M. and Stroosma, Olaf and Delatour, J.},
  year = {2000},
  month = aug,
  publisher = {{American Institute of Aeronautics and Astronautics}},
  address = {{Denver,CO,U.S.A.}},
  doi = {10.2514/6.2000-4503},
  url = {http://arc.aiaa.org/doi/10.2514/6.2000-4503},
  urldate = {2020-09-14},
  file = {C\:\\Users\\nwmbeckers\\Dropbox\\library-tud\\van Paassen2000_DUECA - Data-driven activation in distributed real-time computation.pdf},
  language = {en}
}


@article{melman2017_does,
  title = {Does Haptic Steering Guidance Instigate Speeding? {{A}} Driving Simulator Study into Causes and Remedies},
  shorttitle = {Does Haptic Steering Guidance Instigate Speeding?},
  author = {Melman, T. and {de Winter}, J.C.F. and Abbink, D.A.},
  year = {2017},
  month = jan,
  volume = {98},
  pages = {372--387},
  issn = {00014575},
  doi = {10.1016/j.aap.2016.10.016},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0001457516303773},
  urldate = {2020-03-20},
  abstract = {An important issue in road traffic safety is that drivers show adverse behavioral adaptation (BA) to driver assistance systems. Haptic steering guidance is an upcoming assistance system which facilitates lanekeeping performance while keeping drivers in the loop, and which may be particularly prone to BA. Thus far, experiments on haptic steering guidance have measured driver performance while the vehicle speed was kept constant. The aim of the present driving simulator study was to examine whether haptic steering guidance causes BA in the form of speeding, and to evaluate two types of haptic steering guidance designed not to suffer from BA. Twenty-four participants drove a 1.8 m wide car for 13.9 km on a curved road, with cones demarcating a single 2.2 m narrow lane. Participants completed four conditions in a counterbalanced design: no guidance (Manual), continuous haptic guidance (Cont), continuous guidance that linearly reduced feedback gains from full guidance at 125 km/h towards manual control at 130 km/h and above (ContRF), and haptic guidance provided only when the predicted lateral position was outside a lateral bandwidth (Band). Participants were familiarized with each condition prior to the experimental runs and were instructed to drive as they normally would while minimizing the number of cone hits. Compared to Manual, the Cont condition yielded a significantly higher driving speed (on average by 7 km/h), whereas ContRF and Band did not. All three guidance conditions yielded better lane-keeping performance than Manual, whereas Cont and ContRF yielded lower self-reported workload than Manual. In conclusion, continuous steering guidance entices drivers to increase their speed, thereby diminishing its potential safety benefits. It is possible to prevent BA while retaining safety benefits by making a design adjustment either in lateral (Band) or in longitudinal (ContRF) direction.},
  file = {C\:\\Users\\nwmbeckers\\Dropbox\\library-tud\\Melman2017_Does haptic steering guidance instigate speeding_Accident Analysis & Prevention2.pdf},
  journal = {Accident Analysis \& Prevention},
  language = {en}
}

@article{di2020_survey,
abstract = {This paper serves as an introduction and overview of the potentially useful models and methodologies from artificial intelligence (AI) into the field of transportation engineering for autonomous vehicle (AV) control in the era of mixed autonomy when AVs drive alongside human-driven vehicles (HV). It is the first-of-its-kind survey paper to comprehensively review literature in both transportation engineering and AI for mixed traffic modeling. We will discuss state-of-the-art applications of AI-guided methods, identify opportunities and obstacles, and raise open questions. We divide the stage of AV deployment into four phases: the pure HVs, the HV-dominated, the AV-dominated, and the pure AVs. This paper is primarily focused on the latter three phases. Models used for each phase are summarized, encompassing game theory, deep (reinforcement) learning, and imitation learning. While reviewing the methodologies, we primarily focus on the following research questions: (1) What scalable driving policies are to control a large number of AVs in mixed traffic comprised of human drivers and uncontrollable AVs? (2) How do we estimate human driver behaviors? (3) How should the driving behavior of uncontrollable AVs be modeled in the environment? (4) How are the interactions between human drivers and autonomous vehicles characterized? We also provide a list of public datasets and simulation software related to AVs. Hopefully this paper will not only inspire our transportation community to rethink the conventional models that are developed in the data-shortage era, but also start conversations with other disciplines, in particular robotics and machine learning, to join forces towards creating a safe and efficient mixed traffic ecosystem.},
archivePrefix = {arXiv},
arxivId = {2007.05156},
author = {Di, Xuan and Shi, Rongye},
doi = {10.1016/j.trc.2021.103008},
eprint = {2007.05156},
file = {:C\:/Users/Olger/Documents/Mendeley/1-s2.0-S0968090X21000401-main.pdf:pdf},
issn = {0968090X},
journal = {Transportation Research Part C: Emerging Technologies},
keywords = {Artificial intelligence (AI),Autonomous vehicle (AV) control,Mixed autonomy},
number = {July 2020},
pages = {103008},
publisher = {Elsevier Ltd},
title = {{A survey on autonomous vehicle control in the era of mixed-autonomy: From physics-based to AI-guided driving policy learning}},
url = {https://doi.org/10.1016/j.trc.2021.103008},
volume = {125},
year = {2021}
}

@article{Silvera2022,
abstract = {Simulators are an essential tool for behavioural and interaction research on driving, due to the safety, cost, and experimental control issues of on-road driving experiments. The most advanced simulators use expensive 360 degree projections systems to ensure visual fidelity, full field of view, and immersion. However, similar visual fidelity can be achieved affordably using a virtual reality (VR) based visual interface. We present DReyeVR, an open-source VR based driving simulator platform designed with behavioural and interaction research priorities in mind. DReyeVR (read "driver") is based on Unreal Engine and the CARLA autonomous vehicle simulator and has features such as eye tracking, a functional driving heads-up display (HUD) and vehicle audio, custom definable routes and traffic scenarios, experimental logging, replay capabilities, and compatibility with ROS. We describe the hardware required to deploy this simulator for under $5000$ USD, much cheaper than commercially available simulators. Finally, we describe how DReyeVR may be leveraged to answer an interaction research question in an example scenario.},
archivePrefix = {arXiv},
arxivId = {2201.01931},
author = {Silvera, Gustavo and Biswas, Abhijat and Admoni, Henny},
eprint = {2201.01931},
file = {:C\:/Users/Olger/Documents/Mendeley/2201.01931.pdf:pdf},
month = {jan},
title = {{DReyeVR: Democratizing Virtual Reality Driving Simulation for Behavioural & Interaction Research}},
url = {http://arxiv.org/abs/2201.01931},
year = {2022}
}

@article{Melman2021,
abstract = {Modern computerized vehicles offer the possibility of changing vehicle parameters with the aim of creating a novel driving experience, such as an increased feeling of sportiness. For example, electric vehicles can be designed to provide an artificial sound, and the throttle mapping can be adjusted to give drivers the illusion that they are driving a sports vehicle (i.e., without altering the vehicle's performance envelope). However, a fundamental safety-related question is how drivers perceive and respond to vehicle parameter adjustments. As of today, human-subject research on throttle mapping is unavailable, whereas research on sound enhancement is mostly conducted in listening rooms, which provides no insight into how drivers respond to the auditory cues. This study investigated how perceived sportiness and driving behavior are affected by adjustments in vehicle sound and throttle mapping. Through a within-subject simulator-based experiment, we investigated (1) Modified Throttle Mapping (MTM), (2) Artificial Engine Sound (AES) via a virtually elevated rpm, and (3) MTM and AES combined, relative to (4) a Baseline condition and (5) a Sports car that offered increased engine power. Results showed that, compared to Baseline, AES and MTM-AES increased perceived sportiness and yielded a lower speed variability in curves. Furthermore, MTM and MTM-AES caused higher vehicle acceleration than Baseline during the first second of driving away from a standstill. Mean speed and comfort ratings were unaffected by MTM and AES. The highest sportiness ratings and fastest driving speeds were obtained for the Sports car. In conclusion, the sound enhancement not only increased the perception of sportiness but also improved drivers' speed control performance, suggesting that sound is used by drivers as functional feedback. The fact that MTM did not affect the mean driving speed indicates that drivers adapted their “gain” to the new throttle mapping and were not susceptible to risk compensation.},
author = {Melman, Timo and Visser, Peter and Mouton, Xavier and de Winter, Joost},
doi = {10.1155/2021/4396401},
editor = {de Luca, Stefano},
file = {:C\:/Users/Olger/Documents/Mendeley/Creating_the_Illusion_of_Sportiness_Evaluating_Mod.pdf:pdf},
issn = {2042-3195},
journal = {Journal of Advanced Transportation},
month = {oct},
pages = {1--15},
title = {{Creating the Illusion of Sportiness: Evaluating Modified Throttle Mapping and Artificial Engine Sound for Electric Vehicles}},
url = {https://www.hindawi.com/journals/jat/2021/4396401/},
volume = {2021},
year = {2021}
}

